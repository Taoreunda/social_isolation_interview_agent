"""ì €ì¥ëœ ì¸í„°ë·° ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” í˜ì´ì§€."""

from __future__ import annotations

import asyncio
from datetime import datetime
from typing import Dict, List

import json
from functools import lru_cache

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
import sys
from pathlib import Path
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate

ROOT_DIR = Path(__file__).resolve().parents[1]
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

from app_core.auth import render_user_badge, require_admin_login
from app_core.config import bootstrap, get_config_value
from storage import JSONStorage

bootstrap()

st.set_page_config(
    page_title="ê²°ê³¼ ë¶„ì„ - ì‚¬íšŒì  ê³ ë¦½ ì¸í„°ë·°",
    page_icon="ğŸ“Š",
    layout="wide",
)

st.markdown(
    """
<style>
    .analysis-header { text-align: center; color: #2E86AB; margin-bottom: 2rem; }
    .metric-card { background-color: #ffffff; border: 2px solid #e3f2fd; border-radius: 10px; padding: 1rem; text-align: center; }
    .diagnosis-hikikomori { background-color: #ffebee; border-left: 5px solid #f44336; padding: 1rem; margin: 0.5rem 0; }
    .diagnosis-isolation { background-color: #fff3e0; border-left: 5px solid #ff9800; padding: 1rem; margin: 0.5rem 0; }
    .diagnosis-normal { background-color: #e8f5e8; border-left: 5px solid #4caf50; padding: 1rem; margin: 0.5rem 0; }
</style>
""",
    unsafe_allow_html=True,
)

if not require_admin_login("result"):
    st.stop()

render_user_badge("result")


def initialize_analysis_state() -> None:
    if "storage" not in st.session_state:
        st.session_state.storage = JSONStorage()
    if "analysis_llm" not in st.session_state:
        try:
            google_api_key = get_config_value("GOOGLE_API_KEY")
            if not google_api_key:
                raise RuntimeError("GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            st.session_state.analysis_llm = ChatGoogleGenerativeAI(
                model="gemini-2.5-flash",
                google_api_key=google_api_key,
                temperature=0.2,
                max_output_tokens=1024,
            )
        except Exception as exc:  # pragma: no cover - í™˜ê²½ ì˜ì¡´
            st.session_state.analysis_llm = None
            st.session_state.analysis_llm_error = str(exc)
    if "analysis_llm_error" not in st.session_state:
        st.session_state.analysis_llm_error = None


def load_all_results() -> List[Dict]:
    try:
        return st.session_state.storage.get_all_results()
    except Exception as exc:  # pragma: no cover
        st.error(f"ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
        return []


def create_diagnosis_chart(results: List[Dict]):
    if not results:
        return None

    diagnosis_counts: Dict[str, int] = {}
    for result in results:
        diagnosis = result.get("final_diagnosis") or "ë¯¸ë¶„ë¥˜"
        diagnosis_counts[diagnosis] = diagnosis_counts.get(diagnosis, 0) + 1

    return px.pie(
        values=list(diagnosis_counts.values()),
        names=list(diagnosis_counts.keys()),
        title="ì§„ë‹¨ ê²°ê³¼ ë¶„í¬",
        color_discrete_map={
            "íˆí‚¤ì½”ëª¨ë¦¬": "#ff6b6b",
            "ì‚¬íšŒì  ê³ ë¦½": "#feca57",
            "ì¼ë°˜": "#48ca99",
            "ë¯¸ë¶„ë¥˜": "#a4b0be",
        },
    )


def create_criteria_analysis_chart(results: List[Dict]):
    if not results:
        return None

    criteria_totals = {"A": 0, "B": 0, "C": 0, "D": 0}
    total = len(results)

    for result in results:
        criteria = result.get("criteria_results", {})
        for key in criteria_totals:
            if criteria.get(key) is True:
                criteria_totals[key] += 1

    percentages = {key: (value / total * 100) if total > 0 else 0 for key, value in criteria_totals.items()}

    fig = go.Figure(
        data=[
            go.Bar(
                x=list(percentages.keys()),
                y=list(percentages.values()),
                marker_color=["#3498db", "#e74c3c", "#f39c12", "#2ecc71"],
            )
        ]
    )
    fig.update_layout(title="ê¸°ì¤€ë³„ ì¶©ì¡±ë¥  (%)", xaxis_title="í‰ê°€ ê¸°ì¤€", yaxis_title="ì¶©ì¡±ë¥  (%)", yaxis=dict(range=[0, 100]))
    return fig


def create_timeline_chart(results: List[Dict]):
    if not results:
        return None

    date_counts: Dict[str, int] = {}
    for result in results:
        completed = result.get("completed_at")
        if completed:
            date = completed.split("T")[0]
            date_counts[date] = date_counts.get(date, 0) + 1

    if not date_counts:
        return None

    sorted_dates = sorted(date_counts.keys())
    counts = [date_counts[date] for date in sorted_dates]

    fig = go.Figure(
        data=go.Scatter(
            x=sorted_dates,
            y=counts,
            mode="lines+markers",
            line=dict(color="#3498db", width=3),
            marker=dict(size=8),
        )
    )
    fig.update_layout(title="ì¼ë³„ ì¸í„°ë·° ì‹¤ì‹œ í˜„í™©", xaxis_title="ë‚ ì§œ", yaxis_title="ì¸í„°ë·° ìˆ˜")
    return fig



def display_result_details(result: Dict) -> None:
    st.subheader(f"ğŸ“‹ ì„¸ì…˜ {result.get('session_id')} ìƒì„¸ ì •ë³´")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì™„ë£Œ ì‹œê°„", (result.get("completed_at") or "").split("T")[0])
    with col2:
        st.metric("ëŒ€í™” ìˆ˜", result.get("conversation_length", 0))
    with col3:
        st.metric("ì¬ì§ˆë¬¸ íšŸìˆ˜", result.get("total_clarifications", 0))

    diagnosis = result.get("final_diagnosis", "ë¯¸ë¶„ë¥˜")
    if diagnosis == "íˆí‚¤ì½”ëª¨ë¦¬":
        klass = "diagnosis-hikikomori"
        st.markdown(f'<div class="{klass}"><strong>ğŸ” ì§„ë‹¨ ê²°ê³¼:</strong> {diagnosis}</div>', unsafe_allow_html=True)
    elif diagnosis == "ì‚¬íšŒì  ê³ ë¦½":
        klass = "diagnosis-isolation"
        st.markdown(f'<div class="{klass}"><strong>ğŸ” ì§„ë‹¨ ê²°ê³¼:</strong> {diagnosis}</div>', unsafe_allow_html=True)
    elif diagnosis == "ì¶”ê°€ í‰ê°€ í•„ìš”":
        st.warning("ğŸ” ì§„ë‹¨ ê²°ê³¼: ì¶”ê°€ í‰ê°€ í•„ìš”")
    else:
        st.info(f"ğŸ” ì§„ë‹¨ ê²°ê³¼: {diagnosis}")

    st.subheader("ğŸ“Š ê¸°ì¤€ë³„ í‰ê°€ ê²°ê³¼")
    criteria = result.get("criteria_results", {})
    col_a, col_b, col_c, col_d = st.columns(4)

    abc_all_negative = all(criteria.get(k) is False for k in ("A", "B", "C"))

    def render_criterion(column, key: str, label: str) -> None:
        value = criteria.get(key)
        if value is True:
            column.success(f"{label}\nâœ… ì¶©ì¡±")
        elif value is False:
            column.info(f"{label}\nâŒ ë¹„ì¶©ì¡±")
        elif (
            key == "D"
            and diagnosis == "ì¼ë°˜"
            and abc_all_negative
            and value in (None, "")
        ):
            column.info(f"{label}\nğŸš« í‰ê°€ ìƒëµ")
        else:
            column.warning(f"{label}\nâ³ í‰ê°€ ì¤‘")

    render_criterion(col_a, "A", "ğŸ  A ê¸°ì¤€")
    render_criterion(col_b, "B", "ğŸ‘¥ B ê¸°ì¤€")
    render_criterion(col_c, "C", "ğŸ¤ C ê¸°ì¤€")
    render_criterion(col_d, "D", "ğŸ˜Ÿ D ê¸°ì¤€")

    question_map, question_order = load_flow_question_map()

    conversation = result.get("conversation_history", [])
    if conversation:
        with st.expander("ğŸ—’ï¸ ë©´ë‹´ ëŒ€í™” ê¸°ë¡"):
            for entry in conversation:
                content = entry.get("content", "")
                if not content:
                    continue
                role = entry.get("role", "assistant")
                speaker = "ğŸ‘¤ ì‚¬ìš©ì" if role == "user" else "ğŸ¤– ì—ì´ì „íŠ¸"
                st.markdown(f"**{speaker}:** {content}")

    question_results = result.get("question_results", {})
    if question_results:
        with st.expander("ğŸ“‘ ê¸°ë¡ì§€ ì‘ë‹µ ìš”ì•½"):
            rows = []
            for qid, info in question_results.items():
                extracted = (
                    info.get("extracted_value")
                    or info.get("extracted_number")
                    or info.get("extracted_months")
                    or info.get("extracted_score")
                )
                rows.append({
                    "ì½”ë“œ": qid,
                    "ì§ˆë¬¸": question_map.get(qid, qid),
                    "í‰ê°€": info.get("status"),
                    "ì¶”ì¶œê°’": extracted if extracted is not None else "",
                    "ê·¼ê±°": info.get("rationale"),
                    "ê¸°ë¡ì‹œê°": info.get("timestamp"),
                })

            rows.sort(key=lambda row: question_order.get(row["ì½”ë“œ"], 999))
            df = pd.DataFrame(rows)
            string_columns = ["ì½”ë“œ", "ì§ˆë¬¸", "í‰ê°€", "ì¶”ì¶œê°’", "ê·¼ê±°", "ê¸°ë¡ì‹œê°"]
            for column in string_columns:
                if column in df.columns:
                    df[column] = df[column].fillna("").astype("string")
            st.dataframe(df, width="stretch", hide_index=True)


@lru_cache(maxsize=1)
def load_flow_question_map():
    with open("interview_flow.json", "r", encoding="utf-8") as file:
        data = json.load(file)

    question_map = {}
    order_map = {}
    idx = 0
    for node_id, node in data.get("nodes", {}).items():
        if node.get("type") == "question":
            question_map[node_id] = node.get("question_text", "")
            order_map[node_id] = idx
            idx += 1

    return question_map, order_map


def main() -> None:
    initialize_analysis_state()

    results = load_all_results()
    if not results:
        st.warning("ë¶„ì„í•  ì¸í„°ë·° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì¸í„°ë·°ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        if st.button("ğŸ  ë©”ì¸ í˜ì´ì§€ë¡œ ëŒì•„ê°€ê¸°"):
            st.switch_page("main.py")
        return

    st.markdown('<h1 class="analysis-header">ğŸ“Š ì¸í„°ë·° ê²°ê³¼ ë¶„ì„</h1>', unsafe_allow_html=True)

    tab1, tab2 = st.tabs(["ğŸ“ˆ ì „ì²´ í†µê³„", "ğŸ“‹ ê°œë³„ ê²°ê³¼"])

    with tab1:
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.metric("ì´ ì¸í„°ë·° ìˆ˜", len(results))
            st.markdown('</div>', unsafe_allow_html=True)
        with col2:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.metric("íˆí‚¤ì½”ëª¨ë¦¬", sum(1 for r in results if r.get("final_diagnosis") == "íˆí‚¤ì½”ëª¨ë¦¬"))
            st.markdown('</div>', unsafe_allow_html=True)
        with col3:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.metric("ì‚¬íšŒì  ê³ ë¦½", sum(1 for r in results if r.get("final_diagnosis") == "ì‚¬íšŒì  ê³ ë¦½"))
            st.markdown('</div>', unsafe_allow_html=True)
        with col4:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.metric("ì¼ë°˜", sum(1 for r in results if r.get("final_diagnosis") == "ì¼ë°˜"))
            st.markdown('</div>', unsafe_allow_html=True)

        diag_chart = create_diagnosis_chart(results)
        if diag_chart:
            st.plotly_chart(diag_chart, width="stretch")

    with tab2:
        session_options = [
            f"{result.get('session_id')} ({(result.get('completed_at') or '').split('T')[0]})"
            for result in results
        ]
        selected_idx = st.selectbox(
            "ë¶„ì„í•  ì¸í„°ë·°ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            range(len(session_options)),
            format_func=lambda idx: session_options[idx],
        )
        if selected_idx is not None:
            display_result_details(results[selected_idx])

    st.divider()
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("ğŸ  ë©”ì¸ í˜ì´ì§€ë¡œ ëŒì•„ê°€ê¸°"):
            st.switch_page("main.py")
    with col2:
        if st.button("ğŸ“„ CSVë¡œ ë‚´ë³´ë‚´ê¸°"):
            export_success = st.session_state.storage.export_results_csv("interview_results.csv")
            if export_success:
                st.success("ê²°ê³¼ê°€ CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ì¡ŒìŠµë‹ˆë‹¤!")
            else:
                st.error("CSV ë‚´ë³´ë‚´ê¸°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    with col3:
        if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
            st.rerun()


if __name__ == "__main__":  # pragma: no cover
    main()
